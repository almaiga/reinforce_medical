# Setup From Scratch - Complete Guide

## ğŸ¯ Starting Fresh

This guide assumes you're starting from scratch on your SSH server.

---

## ğŸ“‹ Step-by-Step Setup

### Step 1: Download Self-RedTeam Repository (2 min)

```bash
# Download Self-RedTeam (without .git to avoid conflicts)
./download_selfplay_redteaming.sh
```

This will:
- Clone https://github.com/mickelliu/selfplay-redteaming
- Remove .git directory (to avoid conflicts with your repo)
- Verify download

**Verify:**
```bash
ls selfplay-redteaming-reference/
# Should show: openrlhf/, red_team/, scripts/, etc.
```

---

### Step 2: Install Dependencies (5-10 min)

```bash
# Install OpenRLHF and dependencies
./install_dependencies.sh
```

This will:
- Install flash-attn from conda-forge (pre-built, fast)
- Install OpenRLHF from Self-RedTeam fork
- Copy medical_team as red_team module
- Install other requirements

**Verify:**
```bash
python -c "import openrlhf; print('âœ… OpenRLHF OK')"
ls selfplay-redteaming-reference/red_team/__init__.py
```

---

### Step 3: Download Model (10-15 min)

```bash
# Optional: Install hf_transfer for faster downloads
pip install hf_transfer
export HF_HUB_ENABLE_HF_TRANSFER=1

# Download model
./download_model.sh
```

**Verify:**
```bash
ls trainer_output/qwen3-4b-medical-selfplay-sft/config.json
# Should exist
```

---

### Step 4: Generate Training Data (2-3 min)

```bash
# Generate 638 training samples
python scripts/create_rl_training_data.py

# Convert to OpenRLHF format
python scripts/convert_to_openrlhf_format.py
```

**Verify:**
```bash
wc -l data/medical_openrlhf/train.jsonl
# Should show: 638
```

---

### Step 5: Launch Training! (1-2 hours)

```bash
./launch_training.sh
```

---

## ğŸš€ Quick Setup (All Commands)

```bash
# 1. Download Self-RedTeam
./download_selfplay_redteaming.sh

# 2. Install dependencies
./install_dependencies.sh

# 3. Download model (with fast transfer)
pip install hf_transfer
export HF_HUB_ENABLE_HF_TRANSFER=1
./download_model.sh

# 4. Generate data
python scripts/create_rl_training_data.py
python scripts/convert_to_openrlhf_format.py

# 5. Train!
./launch_training.sh
```

---

## ğŸ“ What Gets Created

```
medical_reward_0/
â”œâ”€â”€ selfplay-redteaming-reference/  â† Downloaded (no .git)
â”‚   â”œâ”€â”€ openrlhf/                   â† OpenRLHF with REINFORCE++
â”‚   â”œâ”€â”€ red_team/                   â† Copied from medical_team/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ trainer_output/
â”‚   â””â”€â”€ qwen3-4b-medical-selfplay-sft/  â† Downloaded model
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ medical_rl_training/
â”‚   â”‚   â””â”€â”€ train.jsonl             â† Intermediate format
â”‚   â””â”€â”€ medical_openrlhf/
â”‚       â””â”€â”€ train.jsonl             â† OpenRLHF format (638 samples)
â””â”€â”€ checkpoints/                    â† Created during training
    â””â”€â”€ medical_selfplay_RL_<timestamp>/
```

---

## âœ… Verification Checklist

Before training, verify everything:

```bash
# 1. Self-RedTeam downloaded
ls selfplay-redteaming-reference/openrlhf/

# 2. OpenRLHF installed
python -c "import openrlhf; print('OK')"

# 3. red_team module
ls selfplay-redteaming-reference/red_team/__init__.py

# 4. Model downloaded
ls trainer_output/qwen3-4b-medical-selfplay-sft/config.json

# 5. Data generated
wc -l data/medical_openrlhf/train.jsonl  # Should be 638

# 6. GPU available
nvidia-smi  # Should show RTX PRO 6000
```

All should succeed!

---

## ğŸš¨ Troubleshooting

### Issue: Git conflicts

**Problem:** "fatal: destination path 'selfplay-redteaming-reference' already exists"

**Solution:**
```bash
rm -rf selfplay-redteaming-reference
./download_selfplay_redteaming.sh
```

---

### Issue: OpenRLHF build error

**Error:** "Failed to build 'rlhf'"

**Solution:**
```bash
# Install build dependencies
pip install wheel setuptools build

# Install PyTorch first
pip install torch --index-url https://download.pytorch.org/whl/cu118

# Retry
./install_dependencies.sh
```

---

### Issue: flash-attn compilation

**Error:** "Failed building wheel for flash-attn"

**Solution:** Use conda-forge (pre-built):
```bash
conda install -c conda-forge flash-attn -y
```

This is already in `install_dependencies.sh`!

---

### Issue: Model download slow

**Solution:** Use hf_transfer:
```bash
pip install hf_transfer
export HF_HUB_ENABLE_HF_TRANSFER=1
./download_model.sh
```

---

## ğŸ“Š Expected Output

### After download_selfplay_redteaming.sh:
```
âœ… Self-RedTeam Downloaded Successfully!
âœ… OpenRLHF directory found
âš ï¸  red_team directory not found (will be replaced with medical_team)
```

### After install_dependencies.sh:
```
âœ… flash-attn installed
âœ… OpenRLHF installed
âœ… medical_team copied as red_team
âœ… Requirements installed
âœ… OpenRLHF imported successfully
âœ… red_team module ready
```

### After download_model.sh:
```
âœ… Model Downloaded Successfully!
âœ… Model files verified
```

### After data generation:
```
âœ… Converted 638 records
ğŸ“Š Distribution:
   - adversarial_benign: 159 (25.0%)
   - adversarial_harmful: 159 (25.0%)
   - vanilla_benign: 160 (25.0%)
   - vanilla_harmful: 160 (25.0%)
```

---

## â±ï¸ Time Estimates

- Download Self-RedTeam: 2 min
- Install dependencies: 5-10 min
- Download model: 10-15 min (5 min with hf_transfer)
- Generate data: 2-3 min
- **Setup total: ~20-30 min**
- Training: 1-2 hours

**Total: ~2-2.5 hours from scratch to trained model!**

---

## ğŸ¯ Why This Approach?

### Self-RedTeam Fork (Not Official OpenRLHF)
- âœ… Has REINFORCE++ implementation
- âœ… Has self-play game logic
- âœ… Tested with the paper
- âŒ Official OpenRLHF doesn't have these features

### No .git Directory
- âœ… Avoids conflicts with your main repo
- âœ… Cleaner git status
- âœ… Still get all the code
- âœ… Already in .gitignore

### medical_team as red_team
- âœ… OpenRLHF expects module named "red_team"
- âœ… Our medical_team is adapted from their red_team
- âœ… Drop-in replacement
- âœ… Works perfectly

---

## ğŸ“š Key Files

- `download_selfplay_redteaming.sh` - Download Self-RedTeam (no .git)
- `install_dependencies.sh` - Install OpenRLHF & deps
- `download_model.sh` - Download fine-tuned model
- `launch_training.sh` - Main training launcher

---

## ğŸ‰ You're Ready!

Once all steps complete:

```bash
./launch_training.sh
```

Training will:
- Load models on GPU (~53GB / 96GB)
- Run self-play games
- Save checkpoints every 50 steps
- Complete in 1-2 hours

Monitor with:
```bash
watch -n 1 nvidia-smi
tail -f checkpoints/medical_selfplay_RL_*/logs/training.log
```

Good luck! ğŸš€
