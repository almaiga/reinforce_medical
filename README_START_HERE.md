# ðŸš€ START HERE - Medical Self-Play Training

## âœ… Complete Setup in 5 Commands

```bash
# 1. Download Self-RedTeam (2 min)
./download_selfplay_redteaming.sh

# 2. Install dependencies (5-10 min)
./install_dependencies.sh

# 3. Download model (10-15 min)
pip install hf_transfer && export HF_HUB_ENABLE_HF_TRANSFER=1
./download_model.sh

# 4. Generate data (2-3 min)
python scripts/create_rl_training_data.py
python scripts/convert_to_openrlhf_format.py

# 5. Train! (1-2 hours)
./launch_training.sh
```

**Total time: ~2-2.5 hours from scratch to trained model!**

---

## ðŸ“š Documentation

- **`SETUP_FROM_SCRATCH.md`** - Complete step-by-step guide
- **`QUICK_REFERENCE.md`** - One-page reference
- **`HUGGINGFACE_DOWNLOAD_GUIDE.md`** - Model download guide
- **`RTX_PRO_6000_OPTIMIZED.md`** - GPU-specific optimizations

---

## ðŸŽ¯ What You're Building

**Medical Self-Play Training** using REINFORCE++ from the Self-RedTeam paper:
- **Attacker**: Introduces realistic medical errors
- **Assessor**: Detects medical errors
- **Both improve** through self-play co-evolution

---

## ðŸ’» Your Hardware

- **GPU**: RTX PRO 6000 (96GB VRAM) - Perfect! ðŸš€
- **Memory usage**: ~53GB / 96GB (55%)
- **Training time**: 1-2 hours per epoch
- **Batch size**: 64 rollout, 16 train (optimized for 96GB)

---

## ðŸ“¦ What Gets Installed

1. **Self-RedTeam Repository** (without .git)
   - OpenRLHF with REINFORCE++
   - Self-play game logic
   - Reference code

2. **Dependencies**
   - flash-attn (from conda-forge)
   - OpenRLHF (from Self-RedTeam fork)
   - PyTorch, transformers, etc.

3. **Your Fine-Tuned Model**
   - Abdine/qwen3-4b-medical-selfplay-sft
   - ~8GB download

4. **Training Data**
   - 638 samples (4-way balanced)
   - Generated from MEDEC dataset

---

## âœ… Verification

Before training, check:

```bash
# All should succeed:
python -c "import openrlhf; print('âœ… OpenRLHF')"
ls selfplay-redteaming-reference/red_team/__init__.py && echo "âœ… red_team"
ls trainer_output/qwen3-4b-medical-selfplay-sft/config.json && echo "âœ… Model"
wc -l data/medical_openrlhf/train.jsonl && echo "âœ… Data (638)"
nvidia-smi && echo "âœ… GPU"
```

---

## ðŸš¨ Common Issues

### OpenRLHF build error
```bash
pip install wheel setuptools build
pip install torch --index-url https://download.pytorch.org/whl/cu118
./install_dependencies.sh
```

### Model download slow
```bash
pip install hf_transfer
export HF_HUB_ENABLE_HF_TRANSFER=1
./download_model.sh
```

### Git conflicts
```bash
rm -rf selfplay-redteaming-reference
./download_selfplay_redteaming.sh
```

---

## ðŸ“Š Training Output

Checkpoints saved to:
```
checkpoints/medical_selfplay_RL_<timestamp>/
â”œâ”€â”€ ckpt/
â”‚   â”œâ”€â”€ step_50/
â”‚   â”œâ”€â”€ step_100/
â”‚   â””â”€â”€ ...
â””â”€â”€ logs/
    â””â”€â”€ training.log
```

---

## ðŸŽ‰ Ready to Start!

```bash
./download_selfplay_redteaming.sh
```

Then follow the prompts! ðŸš€

---

## ðŸ’¡ Key Points

- âœ… **Self-RedTeam fork** (not official OpenRLHF) - has REINFORCE++
- âœ… **No .git directory** - avoids conflicts with your repo
- âœ… **medical_team â†’ red_team** - OpenRLHF expects this name
- âœ… **Local judge** - no separate server needed
- âœ… **Single GPU** - all models colocated on RTX PRO 6000
- âœ… **Fast training** - 1-2 hours with 96GB VRAM

---

**Questions?** Check `SETUP_FROM_SCRATCH.md` for detailed guide!
