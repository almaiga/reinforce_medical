# âœ… Ready to Train - Single GPU Setup

## ğŸ¯ Optimized for RTX PRO 6000 (96GB VRAM!)

Everything runs on one GPU - no separate servers needed!

**Your GPU is perfect for this!** ğŸš€

---

## ğŸš€ Start Training (2 Commands)

```bash
# 1. Setup (20-30 min)
./quick_start.sh

# 2. Train (1-2 hours with 96GB!)
./launch_training.sh
```

Done! âœ…

---

## ğŸ’¡ What's Different (Single GPU)

### âœ… No Judge Server
- Judge runs **in-process** on same GPU
- No HTTP server to manage
- No network latency
- Simpler and more reliable

### âœ… Optimized Memory
- Batch sizes: 4/16 (optimized for 96GB)
- GPU memory: 75% utilization (~53GB used)
- All models colocated
- Plenty of headroom (43GB free!)

### âœ… Local Reward Function
- File: `medical_team/local_reward_function.py`
- Loads judge model on-demand
- Evaluates in same process
- Caches model after first use

---

## ğŸ“Š What You Get

### Models
- **Training model**: Qwen3-4B (your fine-tuned)
- **Judge model**: MedGemma-4B (local)
- **Both**: 4B models, perfect for RTX PRO 6000

### Training
- **638 samples** (4-way balanced)
- **REINFORCE++** algorithm
- **Zero-sum rewards**
- **1-2 hours** training time (fast with 96GB!)

### Output
- **Checkpoints**: Every 50 steps
- **Location**: `checkpoints/medical_selfplay_RL_<timestamp>/`
- **Format**: HuggingFace compatible

---

## ğŸ”§ Configuration

### GPU Memory (~53GB used / 96GB available)
```
Training model (actor):  ~10GB
Reference model:         ~10GB
Judge model (on-demand): ~10GB
VLLM engine:            ~8GB
Activations/gradients:  ~15GB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:                  ~53GB / 96GB âœ…
Free:                   ~43GB (plenty!)
```

### Batch Sizes (Optimized for 96GB)
```
Rollout: 64 samples/batch  (2x larger!)
Train:   16 samples/batch  (2x larger!)
Micro:   4 samples/step
```

---

## ğŸ“ Key Files

### Scripts
- `launch_training.sh` - Main launcher (checks everything)
- `quick_start.sh` - Initial setup
- `scripts/train_medical_reinforce.sh` - Training script

### Components
- `medical_team/local_reward_function.py` - Local judge
- `medical_team/utils.py` - Reward calculation
- `medical_team/prompts.py` - Game prompts

### Data
- `data/medical_openrlhf/train.jsonl` - 638 samples
- Generated by scripts automatically

---

## ğŸ¯ Monitoring

```bash
# GPU usage (should be 35-45GB)
watch -n 1 nvidia-smi

# Training progress
tail -f checkpoints/medical_selfplay_RL_*/logs/training.log
```

### Success Indicators
- âœ… GPU memory: 50-60GB / 96GB (plenty of room!)
- âœ… GPU utilization: 85-95%
- âœ… Rewards: Both positive and negative
- âœ… Checkpoints: Saving every 50 steps

---

## ğŸš€ Want Even Faster Training?

With 96GB, you can go bigger! Edit `scripts/train_medical_reinforce.sh`:

```bash
# Maximum batch sizes
--micro_rollout_batch_size 8
--rollout_batch_size 128

# Use more GPU memory
--vllm_gpu_memory_utilization 0.85
```

This will use ~70GB and train even faster!

---

## ğŸ“š Documentation

- `SINGLE_GPU_SETUP.md` - Detailed single GPU guide
- `TRAINING_SCRIPTS_README.md` - All scripts explained
- `START_HERE.md` - Quick reference

---

## âœ… Checklist

Before training:

- [ ] Model downloaded (`trainer_output/qwen3-4b-medical-selfplay-sft/`)
- [ ] OpenRLHF installed (`pip install -e selfplay-redteaming-reference/`)
- [ ] Data generated (638 samples in `data/medical_openrlhf/train.jsonl`)
- [ ] GPU available (`nvidia-smi` shows RTX PRO 6000)
- [ ] Disk space (~20GB free)

Then run:
```bash
./launch_training.sh
```

---

## ğŸ‰ Advantages

### vs. Separate Judge Server
- âœ… **Simpler** - One process instead of two
- âœ… **Faster** - No network overhead
- âœ… **Reliable** - Fewer failure points
- âœ… **Efficient** - Better GPU utilization

### For Your Hardware
- âœ… **Excellent fit** - 53GB used / 96GB available (55%)
- âœ… **All 4B models** - Optimal size
- âœ… **Single GPU** - No distributed complexity
- âœ… **Fast training** - 1-2 hours per epoch
- âœ… **Room to grow** - 43GB free for experiments!

---

## ğŸš€ Ready!

Everything is configured for your RTX PRO 6000.

Just run:
```bash
./quick_start.sh && ./launch_training.sh
```

Training will complete in 1-2 hours with your 96GB GPU! ğŸ‰

**See `RTX_PRO_6000_OPTIMIZED.md` for details on your hardware advantages!**
